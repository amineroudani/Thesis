{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5052314-4146-46c0-b3b0-204c64a42755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ThesisFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eace9c37-5145-4048-81a0-24dfd277e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing out newton method\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m positive_roots_b \u001b[38;5;241m=\u001b[39m find_roots_alternative(B[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     42\u001b[0m params \u001b[38;5;241m=\u001b[39m find_x0_alpha_pairs(B, positive_roots_b)\n\u001b[0;32m---> 43\u001b[0m maxima_checks \u001b[38;5;241m=\u001b[39m evaluate_hessian_at_extremas(params, \u001b[43mx_i\u001b[49m, t_i)\n\u001b[1;32m     44\u001b[0m num_minimas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, is_true \u001b[38;5;129;01min\u001b[39;00m maxima_checks \u001b[38;5;28;01mif\u001b[39;00m is_true)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_minimas \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_i' is not defined"
     ]
    }
   ],
   "source": [
    "noise_level = 0.1\n",
    "num_datapoints_original = 8\n",
    "alpha = 1\n",
    "initial_cond = 1\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Number of data points to remove\n",
    "num_remove = 3\n",
    "\n",
    "# New number of data points after removal\n",
    "num_datapoints_reduced = num_datapoints_original - num_remove\n",
    "\n",
    "trials_minimas = []  # Store the number of minima found in each trial for current num_datapoints\n",
    "\n",
    "for _ in range(10):  # Perform 10 trials to average out the effects of randomness\n",
    "    \n",
    "    # Generate original data with specified number of datapoints and noise level\n",
    "    # We place this inside the loop to get actually get randomness with the noise_level.\n",
    "    original_data = data_gen(num_datapoints_original, noise_level, initial_cond, alpha)\n",
    "    x_i_original = np.array(original_data['Data'].values)\n",
    "    t_i_original = np.array(original_data['Time'].values)\n",
    "    \n",
    "    # Randomly select indices to remove\n",
    "    remove_indices = np.random.choice(range(num_datapoints_original), num_remove, replace=False)\n",
    "    \n",
    "    # Create new arrays excluding the selected indices\n",
    "    t_i_reduced = np.delete(t_i_original, remove_indices)\n",
    "    x_i_reduced = np.delete(x_i_original, remove_indices)\n",
    "    data = pd.DataFrame({'Time': t_i_reduced, 'Data': x_i_reduced})\n",
    "    \n",
    "    # Perform the calculations with the reduced dataset as in your original loop\n",
    "    B = groeb(x_i_reduced, t_i_reduced)\n",
    "    positive_roots_b = roots_symbolic(B[1])\n",
    "    params = find_x0_alpha_pairs(B, positive_roots_b)\n",
    "    maxima_checks = evaluate_hessian_at_extremas(params, x_i_reduced, t_i_reduced)\n",
    "    num_minimas = sum(1 for _, is_true in maxima_checks if is_true)\n",
    "    \n",
    "    if num_minimas == 0:\n",
    "        print(\"Testing out newton method\")\n",
    "        positive_roots_b = find_roots_alternative(B[1])\n",
    "        params = find_x0_alpha_pairs(B, positive_roots_b)\n",
    "        maxima_checks = evaluate_hessian_at_extremas(params, x_i_reduced, t_i_reduced)\n",
    "        num_minimas = sum(1 for _, is_true in maxima_checks if is_true)\n",
    "        \n",
    "        if num_minimas == 0: \n",
    "            print(\"No minima found, performing grid search.\")\n",
    "            for param in params:\n",
    "                best_params, is_edge = grid_search_around_extrema(param, data)\n",
    "                best_params2, is_edge2 = grid_search_around_extrema((0,0), data)\n",
    "                if not is_edge or not is_edge2:\n",
    "                    #print(f\"Found a minimum inside the grid at {best_params}.\")\n",
    "                    num_minimas = 1\n",
    "                else:\n",
    "                    pass\n",
    "                    print(f\"Minimum found at the edge for {param}, likely no minimum exists.\")\n",
    "                    # Handle the edge case, possibly by ignoring or taking special note\n",
    "                    #plot(data)\n",
    "\n",
    "    trials_minimas.append(num_minimas)\n",
    "\n",
    "# Calculate statistics for the trials\n",
    "max_minimas = np.max(trials_minimas)\n",
    "mean_minimas = np.mean(trials_minimas)\n",
    "std_minimas = np.std(trials_minimas)\n",
    "results_list.append((num_datapoints_reduced, mean_minimas, std_minimas, max_minimas))\n",
    "\n",
    "# Display results\n",
    "print(f'Number of Datapoints={num_datapoints_reduced}: Mean= {mean_minimas}, Std Dev = {std_minimas}, Max = {max_minimas}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e189669-48b5-4262-befc-724e68fb07a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
